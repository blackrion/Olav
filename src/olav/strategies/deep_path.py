"""
Deep Path Strategy - Hypothesis-driven reasoning for complex diagnostics.

This strategy implements an iterative reasoning loop for "why" questions
and multi-step troubleshooting scenarios that cannot be answered by a
single tool invocation.

Execution Flow (max 5 iterations):
1. ObservationCollect: Gather initial data with tools
2. HypothesisGenerate: LLM analyzes data and forms hypotheses
3. Verification: Execute tools to test hypothesis
4. Refinement: Update understanding based on results
5. Repeat until answer found or max iterations

Example Queries:
- "ä¸ºä»€ä¹ˆ R1 æ— æ³•å»ºç«‹ BGP é‚»å±…ï¼Ÿ" â†’ Multi-step: BGP status â†’ config check â†’ neighbor reachability
- "è¯Šæ–­ä¸ºä»€ä¹ˆè·¯ç”±è¡¨ä¸å®Œæ•´" â†’ Hypothesis loop: OSPF adjacency â†’ route filtering â†’ redistribution
- "æ’æŸ¥ç½‘ç»œä¸¢åŒ…é—®é¢˜" â†’ Iterative: interface errors â†’ QoS policies â†’ path MTU

Key Difference from Fast Path:
- Fast Path: Single tool call, deterministic
- Deep Path: Iterative reasoning, hypothesis-driven, adaptive
"""

import logging
from typing import Any

from langchain_core.language_models import BaseChatModel
from langchain_core.messages import SystemMessage
from pydantic import BaseModel, Field

from olav.tools.base import ToolOutput, ToolRegistry

logger = logging.getLogger(__name__)


class Hypothesis(BaseModel):
    """
    A hypothesis about the root cause of a problem.

    LLM generates hypotheses based on observed data.
    """

    description: str = Field(description="What this hypothesis proposes")
    reasoning: str = Field(description="Why this hypothesis is plausible")
    verification_plan: str = Field(
        description="What tool to use and what to check to verify/reject this hypothesis"
    )
    confidence: float = Field(description="Confidence in this hypothesis (0.0-1.0)", ge=0.0, le=1.0)


class ObservationStep(BaseModel):
    """
    A single observation step in the reasoning loop.

    Contains the tool used, data collected, and LLM's interpretation.
    """

    step_number: int
    tool: str
    parameters: dict[str, Any]
    tool_output: ToolOutput | None = None
    interpretation: str = Field(description="LLM's interpretation of what the data means")


class ReasoningState(BaseModel):
    """
    State of the deep path reasoning process.

    Tracks observations, hypotheses, and current understanding.
    """

    original_query: str
    observations: list[ObservationStep] = Field(default_factory=list)
    hypotheses: list[Hypothesis] = Field(default_factory=list)
    current_hypothesis: Hypothesis | None = None
    iteration: int = 0
    conclusion: str | None = None
    confidence: float = Field(default=0.0, ge=0.0, le=1.0)


class DeepPathStrategy:
    """
    Deep Path execution strategy for complex, multi-step diagnostics.

    Implements hypothesis-driven reasoning:
    1. Collect initial observations
    2. Generate hypotheses about root cause
    3. Verify hypothesis with targeted tool calls
    4. Refine understanding and iterate

    Attributes:
        llm: Language model for reasoning
        tool_registry: Registry of available tools
        max_iterations: Maximum reasoning loops (default: 5)
        confidence_threshold: Min confidence to conclude (default: 0.8)
    """

    def __init__(
        self,
        llm: BaseChatModel,
        tool_registry: "ToolRegistry",
        max_iterations: int = 5,
        confidence_threshold: float = 0.8,
    ) -> None:
        """
        Initialize Deep Path strategy.

        Args:
            llm: Language model for reasoning
            tool_registry: ToolRegistry instance (required for tool discovery)
            max_iterations: Max reasoning iterations
            confidence_threshold: Min confidence to conclude
        """
        self.llm = llm
        self.tool_registry = tool_registry
        self.max_iterations = max_iterations
        self.confidence_threshold = confidence_threshold

        # Load tool capability guides (cached at init)
        self._tool_guides = self._load_tool_capability_guides()

        # Validate tool registry
        if not self.tool_registry:
            msg = "ToolRegistry is required for DeepPathStrategy"
            raise ValueError(msg)

        logger.info(
            f"DeepPathStrategy initialized with max_iterations={max_iterations}, "
            f"confidence_threshold={confidence_threshold}, "
            f"available tools: {len(self.tool_registry.list_tools())}"
        )

    def _load_tool_capability_guides(self) -> dict[str, str]:
        """Load tool capability guides from config/prompts/tools/.
        
        Returns:
            Dict mapping tool prefix to capability guide content
        """
        from olav.core.prompt_manager import prompt_manager
        
        guides = {}
        for tool_prefix in ["suzieq", "netbox", "cli", "netconf"]:
            guide = prompt_manager.load_tool_capability_guide(tool_prefix)
            if guide:
                guides[tool_prefix] = guide
                logger.debug(f"Loaded capability guide for: {tool_prefix}")
        
        return guides

    async def execute(
        self, user_query: str, context: dict[str, Any] | None = None
    ) -> dict[str, Any]:
        """
        Execute Deep Path strategy for a complex query.

        Args:
            user_query: User's diagnostic question
            context: Optional context (network topology, device info, etc.)

        Returns:
            Dict with 'success', 'conclusion', 'reasoning_trace', 'metadata'
        """
        state = ReasoningState(original_query=user_query)

        try:
            # Step 1: Initial observation collection
            logger.info(f"Deep Path iteration {state.iteration}: Initial observation")
            await self._collect_initial_observations(state, context)

            # Reasoning loop
            while state.iteration < self.max_iterations:
                state.iteration += 1
                logger.info(f"Deep Path iteration {state.iteration}/{self.max_iterations}")

                # Step 2: Generate hypotheses
                await self._generate_hypotheses(state)

                if not state.hypotheses:
                    logger.warning("No hypotheses generated, concluding with current data")
                    break

                # Step 3: Select and verify best hypothesis
                state.current_hypothesis = state.hypotheses[0]  # Highest confidence

                logger.info(
                    f"Testing hypothesis: {state.current_hypothesis.description} "
                    f"(confidence: {state.current_hypothesis.confidence:.2f})"
                )

                await self._verify_hypothesis(state)

                # Step 4: Check if we can conclude
                if state.current_hypothesis.confidence >= self.confidence_threshold:
                    logger.info(
                        f"Hypothesis confidence {state.current_hypothesis.confidence:.2f} "
                        f"exceeds threshold {self.confidence_threshold}, concluding"
                    )
                    break

                # Step 5: Refine understanding (implicit in next iteration)

            # Synthesize final conclusion
            await self._synthesize_conclusion(state)

            return {
                "success": True,
                "conclusion": state.conclusion,
                "reasoning_trace": [
                    {
                        "step": obs.step_number,
                        "tool": obs.tool,
                        "interpretation": obs.interpretation,
                    }
                    for obs in state.observations
                ],
                "hypotheses_tested": [
                    {
                        "description": h.description,
                        "confidence": h.confidence,
                        "reasoning": h.reasoning,
                    }
                    for h in state.hypotheses
                ],
                "metadata": {
                    "strategy": "deep_path",
                    "iterations": state.iteration,
                    "final_confidence": state.confidence,
                    "total_observations": len(state.observations),
                },
            }

        except Exception as e:
            logger.exception(f"Deep Path execution failed: {e}")
            return {
                "success": False,
                "reason": "exception",
                "error": str(e),
                "reasoning_trace": [
                    {"step": obs.step_number, "interpretation": obs.interpretation}
                    for obs in state.observations
                ],
            }

    async def _discover_schema(self, user_query: str) -> dict[str, Any] | None:
        """
        Schema-Aware discovery: search schema to find correct tables/fields.
        
        This is CRITICAL for avoiding table name guessing errors.
        
        Args:
            user_query: User's natural language query
            
        Returns:
            Dict mapping table names to their schema info, or None if not applicable
        """
        try:
            schema_tool = self.tool_registry.get_tool("suzieq_schema_search")
            if not schema_tool:
                logger.debug("suzieq_schema_search tool not available")
                return None
            
            from olav.tools.base import ToolOutput
            result = await schema_tool.execute(query=user_query)
            
            if isinstance(result, ToolOutput) and result.data:
                schema_context = {}
                data = result.data
                
                if isinstance(data, dict):
                    tables = data.get('tables', [])
                    for table in tables:
                        if table in data:
                            schema_context[table] = data[table]
                elif isinstance(data, list):
                    for item in data:
                        if isinstance(item, dict) and 'table' in item:
                            schema_context[item['table']] = item
                
                if schema_context:
                    logger.info(f"DeepPath schema discovery found: {list(schema_context.keys())}")
                    return schema_context
                    
            return None
            
        except Exception as e:
            logger.warning(f"Schema discovery failed: {e}")
            return None

    async def _collect_initial_observations(
        self, state: ReasoningState, context: dict[str, Any] | None = None
    ) -> None:
        """
        Collect initial observations to understand the problem.

        Uses Schema-Aware pattern: first discover available tables,
        then LLM decides what tools to call.
        """
        # Schema-Aware: discover correct table names first
        schema_context = await self._discover_schema(state.original_query)
        
        schema_section = ""
        if schema_context:
            schema_tables = "\n".join([
                f"    - {table}: {info.get('description', '')} (fields: {', '.join(info.get('fields', [])[:5])}...)"
                for table, info in schema_context.items()
            ])
            schema_section = f"""
## ğŸ¯ Schema Discovery ç»“æœï¼ˆå¿…é¡»ä½¿ç”¨è¿™äº›è¡¨åï¼‰
{schema_tables}
âš ï¸ é‡è¦ï¼šè¯·ä½¿ç”¨ä¸Šè¿°å‘ç°çš„è¡¨åï¼Œä¸è¦çŒœæµ‹æˆ–ä½¿ç”¨å…¶ä»–è¡¨åï¼
"""
        
        # Build capability guide section
        capability_guide = ""
        if self._tool_guides:
            guides_text = "\n\n".join([
                f"### {name.upper()} å·¥å…·\n{guide[:500]}..."  # Truncate for token efficiency
                for name, guide in self._tool_guides.items()
            ])
            capability_guide = f"""
## å·¥å…·èƒ½åŠ›æŒ‡å—
{guides_text}
"""
        
        context_str = ""
        if context:
            context_str = f"\n\nå¯ç”¨ä¸Šä¸‹æ–‡: {context}"

        prompt = f"""ä½ æ˜¯ OLAV ç½‘ç»œè¯Šæ–­ä¸“å®¶ã€‚ç”¨æˆ·æå‡ºäº†å¤æ‚çš„è¯Šæ–­é—®é¢˜ï¼Œéœ€è¦å¤šæ­¥æ¨ç†ã€‚

## ç”¨æˆ·é—®é¢˜
{state.original_query}
{context_str}
{schema_section}
{capability_guide}
## ç¬¬ä¸€æ­¥ï¼šåˆå§‹è§‚å¯Ÿ
ç¡®å®šéœ€è¦æ”¶é›†å“ªäº›åˆå§‹æ•°æ®æ¥ç†è§£é—®é¢˜ã€‚é€‰æ‹© 1-2 ä¸ªå·¥å…·è°ƒç”¨ã€‚

å¯ç”¨å·¥å…·ï¼š
- suzieq_query: æŸ¥è¯¢ç½‘ç»œçŠ¶æ€ï¼ˆå¿…é¡»ä½¿ç”¨ Schema Discovery ä¸­å‘ç°çš„è¡¨åï¼‰
- netbox_api_call: æŸ¥è¯¢è®¾å¤‡ä¿¡æ¯ã€IPã€é…ç½®
- cli_tool: æ‰§è¡Œ CLI å‘½ä»¤
- netconf_tool: NETCONF get-config

è¿”å› JSON åˆ—è¡¨ï¼š
[
  {{"tool": "<å·¥å…·å>", "parameters": {{"<å‚æ•°å>": "<å‚æ•°å€¼>"}}, "reasoning": "<ä½¿ç”¨è¯¥å·¥å…·çš„ç†ç”±>"}}
]

âš ï¸ å¦‚æœä½¿ç”¨ suzieq_queryï¼Œå¿…é¡»ä½¿ç”¨ Schema Discovery ä¸­å‘ç°çš„è¡¨åï¼
"""

        response = await self.llm.ainvoke([SystemMessage(content=prompt)])

        try:
            import json

            tool_calls = json.loads(response.content)

            for _i, call in enumerate(tool_calls):
                observation = ObservationStep(
                    step_number=len(state.observations) + 1,
                    tool=call["tool"],
                    parameters=call["parameters"],
                    interpretation=call.get("reasoning", ""),
                )

                # Execute tool
                tool_output = await self._execute_tool(call["tool"], call["parameters"])
                observation.tool_output = tool_output

                state.observations.append(observation)

        except Exception as e:
            logger.error(f"Failed to parse initial observation plan: {e}")
            # Fallback: use schema search to discover available tables
            observation = ObservationStep(
                step_number=1,
                tool="suzieq_schema_search",
                parameters={"query": state.original_query},
                interpretation="Fallback: discovering available tables via schema search",
            )
            state.observations.append(observation)

    async def _generate_hypotheses(self, state: ReasoningState) -> None:
        """
        Generate hypotheses based on observations.

        LLM analyzes collected data and proposes possible root causes.
        """
        # Serialize observations
        observations_text = "\n\n".join(
            [
                f"**è§‚å¯Ÿ {obs.step_number}**: {obs.tool} â†’ {obs.interpretation}\n"
                f"æ•°æ®: {obs.tool_output.data[:3] if obs.tool_output and obs.tool_output.data else 'No data'}"
                for obs in state.observations
            ]
        )

        prompt = f"""ä½ æ˜¯ OLAV ç½‘ç»œè¯Šæ–­ä¸“å®¶ã€‚åŸºäºè§‚å¯Ÿåˆ°çš„æ•°æ®ï¼Œæå‡ºå¯èƒ½çš„æ ¹æœ¬åŸå› å‡è®¾ã€‚

## åŸå§‹é—®é¢˜
{state.original_query}

## å·²æ”¶é›†çš„è§‚å¯Ÿ
{observations_text}

## ä»»åŠ¡
åˆ†ææ•°æ®ï¼Œæå‡º 2-3 ä¸ªå…³äºæ ¹æœ¬åŸå› çš„å‡è®¾ã€‚æŒ‰ç½®ä¿¡åº¦æ’åºï¼ˆæœ€å¯èƒ½çš„åœ¨å‰ï¼‰ã€‚

è¿”å› JSON åˆ—è¡¨ï¼š
[
  {{
    "description": "ç®€æ´çš„å‡è®¾æè¿°",
    "reasoning": "ä¸ºä»€ä¹ˆè¿™ä¸ªå‡è®¾åˆç†ï¼ˆåŸºäºè§‚å¯Ÿåˆ°çš„æ•°æ®ï¼‰",
    "verification_plan": "å¦‚ä½•éªŒè¯è¿™ä¸ªå‡è®¾ï¼ˆéœ€è¦ä»€ä¹ˆå·¥å…·å’Œæ•°æ®ï¼‰",
    "confidence": 0.85
  }}
]
"""

        response = await self.llm.ainvoke([SystemMessage(content=prompt)])

        try:
            import json

            hypotheses_data = json.loads(response.content)

            state.hypotheses = [Hypothesis(**h) for h in hypotheses_data]

            # Sort by confidence
            state.hypotheses.sort(key=lambda h: h.confidence, reverse=True)

        except Exception as e:
            logger.error(f"Failed to parse hypotheses: {e}")
            # Fallback hypothesis
            state.hypotheses = [
                Hypothesis(
                    description="éœ€è¦æ›´å¤šæ•°æ®æ¥ç¡®å®šæ ¹æœ¬åŸå› ",
                    reasoning="å½“å‰è§‚å¯Ÿä¸è¶³ä»¥å½¢æˆç¡®å®šæ€§å‡è®¾",
                    verification_plan="æ”¶é›†æ›´å¤šè¯Šæ–­æ•°æ®",
                    confidence=0.3,
                )
            ]

    async def _verify_hypothesis(self, state: ReasoningState) -> None:
        """
        Verify the current hypothesis by executing verification plan.

        Uses Schema-Aware pattern to discover correct table names.
        """
        if not state.current_hypothesis:
            return

        # Schema-Aware: discover correct table names
        schema_context = await self._discover_schema(state.current_hypothesis.verification_plan)
        
        schema_section = ""
        if schema_context:
            schema_tables = "\n".join([
                f"    - {table}: {info.get('description', '')}"
                for table, info in schema_context.items()
            ])
            schema_section = f"""
## ğŸ¯ Schema Discovery ç»“æœï¼ˆå¿…é¡»ä½¿ç”¨è¿™äº›è¡¨åï¼‰
{schema_tables}
"""

        prompt = f"""ä½ æ˜¯ OLAV ç½‘ç»œè¯Šæ–­ä¸“å®¶ã€‚ç°åœ¨éœ€è¦éªŒè¯ä¸€ä¸ªå‡è®¾ã€‚

## å‡è®¾
{state.current_hypothesis.description}

## éªŒè¯è®¡åˆ’
{state.current_hypothesis.verification_plan}
{schema_section}

## ä»»åŠ¡
æ ¹æ®éªŒè¯è®¡åˆ’ï¼Œå†³å®šéœ€è¦æ‰§è¡Œçš„å·¥å…·è°ƒç”¨ã€‚å¦‚æœæœ‰ Schema Discovery ç»“æœï¼Œä½¿ç”¨å‘ç°çš„è¡¨åã€‚

è¿”å› JSONï¼š
{{
  "tool": "<å·¥å…·å>",
  "parameters": {{"<å‚æ•°å>": "<å‚æ•°å€¼>"}},
  "reasoning": "<éªŒè¯ç†ç”±>"
}}

âš ï¸ å¦‚æœä½¿ç”¨ suzieq_queryï¼Œå¿…é¡»ä½¿ç”¨ Schema Discovery ä¸­å‘ç°çš„è¡¨åï¼
"""

        response = await self.llm.ainvoke([SystemMessage(content=prompt)])

        try:
            import json

            verification = json.loads(response.content)

            observation = ObservationStep(
                step_number=len(state.observations) + 1,
                tool=verification["tool"],
                parameters=verification["parameters"],
                interpretation=verification.get("reasoning", ""),
            )

            # Execute tool
            tool_output = await self._execute_tool(verification["tool"], verification["parameters"])
            observation.tool_output = tool_output

            state.observations.append(observation)

            # Update hypothesis confidence based on results
            await self._update_hypothesis_confidence(state)

        except Exception as e:
            logger.error(f"Failed to verify hypothesis: {e}")

    async def _update_hypothesis_confidence(self, state: ReasoningState) -> None:
        """
        Update hypothesis confidence based on verification results.

        LLM analyzes whether verification supports or refutes hypothesis.
        """
        if not state.current_hypothesis:
            return

        latest_obs = state.observations[-1]

        prompt = f"""ä½ æ˜¯ OLAV ç½‘ç»œè¯Šæ–­ä¸“å®¶ã€‚è¯„ä¼°éªŒè¯ç»“æœæ˜¯å¦æ”¯æŒå‡è®¾ã€‚

## å‡è®¾
{state.current_hypothesis.description}

## éªŒè¯ç»“æœ
å·¥å…·: {latest_obs.tool}
æ•°æ®: {latest_obs.tool_output.data[:5] if latest_obs.tool_output and latest_obs.tool_output.data else "No data"}

## ä»»åŠ¡
åˆ†æéªŒè¯ç»“æœæ˜¯å¦æ”¯æŒå‡è®¾ã€‚æ›´æ–°ç½®ä¿¡åº¦ã€‚

è¿”å› JSONï¼š
{{
  "supports_hypothesis": true,
  "updated_confidence": 0.9,
  "reasoning": "éªŒè¯ç»“æœä¸å‡è®¾ä¸€è‡´ï¼Œå¢åŠ ç½®ä¿¡åº¦"
}}
"""

        response = await self.llm.ainvoke([SystemMessage(content=prompt)])

        try:
            import json

            update = json.loads(response.content)

            if update.get("supports_hypothesis"):
                state.current_hypothesis.confidence = update["updated_confidence"]
            else:
                state.current_hypothesis.confidence *= 0.5  # Reduce confidence

            logger.info(
                f"Updated hypothesis confidence to {state.current_hypothesis.confidence:.2f}"
            )

        except Exception as e:
            logger.error(f"Failed to update hypothesis confidence: {e}")

    async def _synthesize_conclusion(self, state: ReasoningState) -> None:
        """
        Synthesize final conclusion from reasoning process.

        LLM creates human-readable answer based on all observations and hypotheses.
        """
        observations_text = "\n".join(
            [f"{obs.step_number}. {obs.tool}: {obs.interpretation}" for obs in state.observations]
        )

        hypotheses_text = "\n".join(
            [f"- {h.description} (ç½®ä¿¡åº¦: {h.confidence:.2f})" for h in state.hypotheses]
        )

        prompt = f"""ä½ æ˜¯ OLAV ç½‘ç»œè¯Šæ–­ä¸“å®¶ã€‚åŸºäºæ¨ç†è¿‡ç¨‹ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

## åŸå§‹é—®é¢˜
{state.original_query}

## æ¨ç†è¿‡ç¨‹
{observations_text}

## æµ‹è¯•çš„å‡è®¾
{hypotheses_text}

## ä»»åŠ¡
ç»¼åˆæ‰€æœ‰ä¿¡æ¯ï¼Œå›ç­”ç”¨æˆ·é—®é¢˜ã€‚åŒ…æ‹¬ï¼š
1. æ ¹æœ¬åŸå› ï¼ˆå¦‚æœæ‰¾åˆ°ï¼‰
2. æ”¯æŒè¯æ®
3. å»ºè®®çš„è§£å†³æ–¹æ¡ˆï¼ˆå¦‚æœé€‚ç”¨ï¼‰

è¿”å› JSONï¼š
{{
  "conclusion": "ç®€æ´æ˜ç¡®çš„ç»“è®ºï¼ˆ2-3 æ®µè¯ï¼‰",
  "confidence": 0.9
}}
"""

        response = await self.llm.ainvoke([SystemMessage(content=prompt)])

        try:
            import json

            result = json.loads(response.content)

            state.conclusion = result["conclusion"]
            state.confidence = result["confidence"]

        except Exception as e:
            logger.error(f"Failed to synthesize conclusion: {e}")
            state.conclusion = f"åŸºäº {len(state.observations)} æ¬¡è§‚å¯Ÿï¼Œé—®é¢˜åˆ†æå°šæœªå®Œæˆã€‚"
            state.confidence = 0.5

    async def _execute_tool(self, tool_name: str, parameters: dict[str, Any]) -> ToolOutput:
        """
        Execute a tool and return standardized output.

        Args:
            tool_name: Tool identifier (must be registered in ToolRegistry)
            parameters: Tool parameters

        Returns:
            ToolOutput from tool execution
        """
        if not self.tool_registry:
            logger.error("ToolRegistry not configured in DeepPathStrategy")
            return ToolOutput(
                source=tool_name,
                device="unknown",
                data=[],
                error="ToolRegistry not configured - cannot execute tools",
            )

        # Get tool from registry
        tool = self.tool_registry.get_tool(tool_name)
        if not tool:
            logger.error(f"Tool '{tool_name}' not found in ToolRegistry")
            available_tools = [t.name for t in self.tool_registry.list_tools()]
            return ToolOutput(
                source=tool_name,
                device="unknown",
                data=[],
                error=f"Tool '{tool_name}' not registered. Available: {', '.join(available_tools)}",
            )

        # Execute tool
        logger.debug(f"Executing tool '{tool_name}' with parameters: {parameters}")
        return await tool.execute(**parameters)

    def is_suitable(self, user_query: str) -> bool:
        """
        Check if query is suitable for Deep Path strategy.

        Args:
            user_query: User's query

        Returns:
            True if suitable for Deep Path, False otherwise
        """
        # Deep Path suitable for:
        # - "Why" questions (ä¸ºä»€ä¹ˆ)
        # - Diagnostic queries (è¯Šæ–­, troubleshoot)
        # - Multi-step analysis

        suitable_patterns = [
            "ä¸ºä»€ä¹ˆ",
            "why",
            "è¯Šæ–­",
            "diagnose",
            "æ’æŸ¥",
            "troubleshoot",
            "åˆ†æ",
            "analyze",
            "investigate",
            "è°ƒæŸ¥",
        ]

        query_lower = user_query.lower()
        return any(pattern in query_lower for pattern in suitable_patterns)
